---
title: Ignite
description: Ignite documentation
---

# Ignite connector

<img src="../_static/img/ignite.png" class="connector-logo">


The Ignite connector allows querying an [Apache Ignite](https://ignite.apache.org/)
database from Trino.

## Requirements

To connect to an Ignite server, you need:

- Ignite version 2.9.0 or latter
- Network access from the Trino coordinator and workers to the Ignite
  server. Port 10800 is the default port.
- Specify `--add-opens=java.base/java.nio=ALL-UNNAMED` in the `jvm.config` when starting the Trino server.

## Configuration

The Ignite connector expose `public` schema by default.

The connector can query an Ignite instance. Create a catalog properties file
that specifies the Ignite connector by setting the `connector.name` to
`ignite`.

For example, to access an instance as `example`, create the file
`etc/catalog/example.properties`. Replace the connection properties as
appropriate for your setup:

```text
connector.name=ignite
connection-url=jdbc:ignite:thin://host1:10800/
connection-user=exampleuser
connection-password=examplepassword
```

The `connection-url` defines the connection information and parameters to pass
to the Ignite JDBC driver. The parameters for the URL are available in the
[Ignite JDBC driver documentation](https://ignite.apache.org/docs/latest/SQL/JDBC/jdbc-driver).
Some parameters can have adverse effects on the connector behavior or not work
with the connector.

The `connection-user` and `connection-password` are typically required and
determine the user credentials for the connection, often a service user. You can
use [secrets ](/docs//security/secrets) to avoid actual values in the catalog
properties files.

### Multiple Ignite servers

If you have multiple Ignite servers you need to configure one
catalog for each server. To add another catalog:

- Add another properties file to `etc/catalog`
- Save it with a different name that ends in `.properties`

For example, if you name the property file `sales.properties`, Trino uses the
configured connector to create a catalog named `sales`.

<!-- Fragment not found: jdbc-common-configurations.fragment -->

<!-- Fragment not found: query-comment-format.fragment -->

<!-- Fragment not found: jdbc-domain-compaction-threshold.fragment -->

<!-- Fragment not found: jdbc-case-insensitive-matching.fragment -->

## Table properties

Table property usage example:

```
CREATE TABLE public.person (
  id BIGINT NOT NULL,
  birthday DATE NOT NULL,
  name VARCHAR(26),
  age BIGINT,
  logdate DATE
)
WITH (
  primary_key = ARRAY['id', 'birthday']
);
```

The following are supported Ignite table properties from [https://ignite.apache.org/docs/latest/sql-reference/ddl](https://ignite.apache.org/docs/latest/sql-reference/ddl)

| Property name | Required | Description |
|---|---|---|


### `primary_key`

This is a list of columns to be used as the table's primary key. If not specified, a `VARCHAR` primary key column named `DUMMY_ID` is generated,
the value is derived from the value generated by the `UUID` function in Ignite.

## Type mapping

The following are supported Ignite SQL data types from [https://ignite.apache.org/docs/latest/sql-reference/data-types](https://ignite.apache.org/docs/latest/sql-reference/data-types)

| Ignite SQL data type name | Map to Trino type | Possible values |
|---|---|---|
| `BOOLEAN` | `BOOLEAN` | `TRUE` and `FALSE` |
| `BIGINT` | `BIGINT` | `-9223372036854775808`, `9223372036854775807`, etc. |
| `DECIMAL` | `DECIMAL` | Data type with fixed precision and scale |
| `DOUBLE` | `DOUBLE` | `3.14`, `-10.24`, etc. |
| `INT` | `INT` | `-2147483648`, `2147483647`, etc. |
| `REAL` | `REAL` | `3.14`, `-10.24`, etc. |
| `SMALLINT` | `SMALLINT` | `-32768`, `32767`, etc. |
| `TINYINT` | `TINYINT` | `-128`, `127`, etc. |
| `CHAR` | `CHAR` | `hello`, `Trino`, etc. |
| `VARCHAR` | `VARCHAR` | `hello`, `Trino`, etc. |
| `DATE` | `DATE` | `1972-01-01`, `2021-07-15`, etc. |


## SQL support

The connector provides read access and write access to data and metadata in
Ignite.  In addition to the [globally available
<sql-globally-available>](#globally available
<sql-globally-available>) and [read operation <sql-read-operations>](#read operation <sql-read-operations>)
statements, the connector supports the following features:

- [](/sql/insert), see also [](ignite-insert)
- [](/sql/update), see also [](ignite-update)
- [](/sql/delete)
- [](/sql/merge), see also [](ignite-merge)
- [](/sql/create-table)
- [](/sql/create-table-as)
- [](/sql/drop-table)
- [](/sql/alter-table), see also [](ignite-alter-table)
- [](ignite-procedures)

(ignite-insert)=
<!-- Fragment not found: non-transactional-insert.fragment -->

### UPDATE limitation

Only `UPDATE` statements with constant assignments and predicates are
supported. For example, the following statement is supported because the values
assigned are constants:

```sql
UPDATE table SET col1 = 1 WHERE col3 = 1
```

Arithmetic expressions, function calls, and other non-constant `UPDATE`
statements are not supported. For example, the following statement is not
supported because arithmetic expressions cannot be used with the `SET`
command:

```sql
UPDATE table SET col1 = col2 + 2 WHERE col3 = 1
```

All column values of a table row cannot be updated simultaneously. For a three
column table, the following statement is not supported:

```sql
UPDATE table SET col1 = 1, col2 = 2, col3 = 3 WHERE col3 = 1
```


### Non-transactional MERGE

The connector supports adding, updating, and deleting rows using [MERGE
statements](/docs/sql/merge), if the `merge.non-transactional-merge.enabled` catalog
property or the corresponding `non_transactional_merge_enabled` catalog session
property is set to `true`. Merge is only supported for directly modifying target
tables.

In rare cases, exceptions may occur during the merge operation, potentially
resulting in a partial update.



(ignite-alter-table)=
<!-- Fragment not found: alter-table-limitation.fragment -->

### Procedures

#### `system.flush_metadata_cache()`

Flush JDBC metadata caches. For example, the following system call
flushes the metadata caches for all schemas in the `example` catalog

```sql
USE example.example_schema;
CALL system.flush_metadata_cache();
```

#### `system.execute('query')`

The `execute` procedure allows you to execute a query in the underlying data
source directly. The query must use supported syntax of the connected data
source. Use the procedure to access features which are not available in Trino
or to execute queries that return no result set and therefore can not be used
with the `query` or `raw_query` pass-through table function. Typical use cases
are statements that create or alter objects, and require native feature such
as constraints, default values, automatic identifier creation, or indexes.
Queries can also invoke statements that insert, update, or delete data, and do
not return any data as a result.

The query text is not parsed by Trino, only passed through, and therefore only
subject to any security or access control of the underlying data source.

The following example sets the current database to the `example_schema` of the
`example` catalog. Then it calls the procedure in that schema to drop the
default value from `your_column` on `your_table` table using the standard SQL
syntax in the parameter value assigned for `query`:

```sql
USE example.example_schema;
CALL system.execute(query => 'ALTER TABLE your_table ALTER COLUMN your_column DROP DEFAULT');
```

Verify that the specific database supports this syntax, and adapt as necessary
based on the documentation for the specific connected database and database
version.


### Pushdown

The connector supports pushdown for a number of operations:

- [join-pushdown](#join-pushdown)
- [limit-pushdown](#limit-pushdown)
- [topn-pushdown](#topn-pushdown)

[Aggregate pushdown <aggregation-pushdown>](#Aggregate pushdown <aggregation-pushdown>) for the following functions:

- {func}`avg`
- {func}`count`
- {func}`max`
- {func}`min`
- {func}`sum`


<!-- Fragment not found: no-pushdown-text-type.fragment -->
